{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import ARCH, GARCH\n",
    "\n",
    "from utilsforecast.losses import *\n",
    "from utilsforecast.evaluation import evaluate\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "from mlforecast import MLForecast\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"NIXTLA_ID_AS_COL\"] = \"true\"\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (9,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/marcopeix/AppliedTimeSeriesForecastingInPython/refs/heads/master/data/AMZN.csv\"\n",
    "df = pd.read_csv(url, parse_dates=['Date'])\n",
    "df.insert(0, 'unique_id', 1)\n",
    "\n",
    "df = df[['unique_id', 'Date', 'Adj Close']]\n",
    "df = df.rename(columns={'Adj Close': 'y', 'Date': 'ds'})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['ds'], df['y'])\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Closing price (USD)')\n",
    "ax.set_title('Daily closing price of AMZN')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get percentage change\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['ds'], df['return'])\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Percentage return (%)')\n",
    "ax.set_title('Daily percentage return of AMZN')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(df['return']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get square of return\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['ds'], df['sq_return'])\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Percentage return (%)')\n",
    "ax.set_title('Daily percentage return of AMZN')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(df['sq_return']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different ARCH models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fit = df[['unique_id', 'ds', 'return']]\n",
    "df_fit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 5\n",
    "\n",
    "# Initialize StatsForecast with ARCH models\n",
    "\n",
    "cv_df = sf.cross_validation(h=h, \n",
    "                            df=df_fit, \n",
    "                            n_windows=10, \n",
    "                            step_size=h,\n",
    "                            target_col='return',\n",
    "                            refit=True)\n",
    "\n",
    "cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = cv_df.merge(df[['ds', 'y']], on='ds', how='left')\n",
    "cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get initial value to inverse transform the percentage change\n",
    "\n",
    "initial_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df['ARCH(1)'] = initial_value * (1+cv_df['ARCH(1)']).cumprod()\n",
    "cv_df['ARCH(2)'] = initial_value * (1+cv_df['ARCH(2)']).cumprod()\n",
    "cv_df['ARCH(3)'] = initial_value * (1+cv_df['ARCH(3)']).cumprod()\n",
    "cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['ds'], df['y'])\n",
    "ax.plot(cv_df['ds'], cv_df['ARCH(1)'], label='ARCH(1)', ls='--')\n",
    "ax.plot(cv_df['ds'], cv_df['ARCH(2)'], label='ARCH(2)', ls=':')\n",
    "ax.plot(cv_df['ds'], cv_df['ARCH(3)'], label='ARCH(3)', ls='-.')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Closing price (USD)')\n",
    "ax.set_title('Daily closing price of AMZN')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = cv_df.drop(['ds', 'cutoff', 'return'], axis=1)\n",
    "evaluation = evaluate(df=eval_df, metrics=[mae])\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize different GARCH models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = StatsForecast(models=[garch1, garch2, garch3], freq='B')\n",
    "\n",
    "cv_df = sf.cross_validation(h=h, \n",
    "                            df=df_fit, \n",
    "                            n_windows=10, \n",
    "                            step_size=h,\n",
    "                            target_col='return',\n",
    "                            refit=True)\n",
    "\n",
    "cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = cv_df.merge(df[['ds', 'y']], on='ds', how='left')\n",
    "cv_df['GARCH(1,1)'] = initial_value * (1+cv_df['GARCH(1,1)']).cumprod()\n",
    "cv_df['GARCH(2,2)'] = initial_value * (1+cv_df['GARCH(2,2)']).cumprod()\n",
    "cv_df['GARCH(3,3)'] = initial_value * (1+cv_df['GARCH(3,3)']).cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['ds'], df['y'])\n",
    "ax.plot(cv_df['ds'], cv_df['GARCH(1,1)'], label='GARCH(1,1)', ls='--')\n",
    "ax.plot(cv_df['ds'], cv_df['GARCH(2,2)'], label='GARCH(2,2)', ls=':')\n",
    "ax.plot(cv_df['ds'], cv_df['GARCH(3,3)'], label='GARCH(3,3)', ls='-.')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Closing price (USD)')\n",
    "ax.set_title('Daily closing price of AMZN')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = cv_df.drop(['ds', 'cutoff', 'return'], axis=1)\n",
    "evaluation = evaluate(df=eval_df, metrics=[mae])\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting with ML models and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'https://raw.githubusercontent.com/panambY/Hourly_Energy_Consumption/master/data/PJM_Load_hourly.csv'\n",
    "df = pd.read_csv(data_url, parse_dates=['Datetime'])\n",
    "df.columns = ['ds', 'y']\n",
    "df.insert(0, 'unique_id', 'PJM')\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "df = df.sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['ds'][-700:], df['y'][-700:])\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Electricity consumption (MW)')\n",
    "ax.set_title('Hourly electricity consumption')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_time = df['ds'].max() - pd.Timedelta(hours=24)\n",
    "\n",
    "df_train = df[df['ds'] <= threshold_time]\n",
    "df_test = df[df['ds'] > threshold_time]\n",
    "\n",
    "print(len(df_train), len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing seasonality and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft, fftfreq\n",
    "\n",
    "def analyze_frequencies(signal, sampling_rate):\n",
    "    \n",
    "    # Perform FFT\n",
    "    \n",
    "    # Get frequencies corresponding to FFT values\n",
    "    # For hourly data, this gives us frequencies in cycles per day\n",
    "    \n",
    "    # Get positive frequencies only (up to Nyquist frequency)\n",
    "    \n",
    "    # Find indices of top 5 amplitudes\n",
    "    \n",
    "    # Get top frequencies and their amplitudes\n",
    "    \n",
    "    return top_frequencies, top_amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_frequencies, top_amplitudes = analyze_frequencies(df_train['y'], sampling_rate=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "    \n",
    "# Create bar plot\n",
    "bars = ax.bar(top_frequencies, top_amplitudes, \n",
    "                color='skyblue',\n",
    "                edgecolor='navy',\n",
    "                width=0.1)  # Adjust width as needed\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.3f}',\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontweight='bold')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('Frequency (cycles/day)', fontsize=12)\n",
    "ax.set_ylabel('Amplitude', fontsize=12)\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from mlforecast.lag_transforms import ExpandingMean, RollingMean\n",
    "from mlforecast.target_transforms import Differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model dict\n",
    "models ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MLForecast object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_cv_df = mlf.cross_validation(\n",
    "    df=df_train,\n",
    "    h=24,\n",
    "    n_windows=7,\n",
    "    step_size=24,\n",
    "    refit=False,\n",
    ")\n",
    "ml_cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(ml_cv_df['ds'], ml_cv_df['y'])\n",
    "ax.plot(ml_cv_df['ds'], ml_cv_df['lgbm'], label='LightGBM', ls='--')\n",
    "ax.plot(ml_cv_df['ds'], ml_cv_df['lasso'], label='Lasso', ls=':')\n",
    "ax.plot(ml_cv_df['ds'], ml_cv_df['gbr'], label='GradientBoosting', ls='-.')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Electricity consumption (MW)')\n",
    "ax.set_title('Hourly electricity consumption')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = ml_cv_df.drop(['ds', 'cutoff'], axis=1)\n",
    "evaluation = evaluate(df=eval_df, metrics=[mae, smape])\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import MSTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstl = MSTL(season_length=[12, 24, 168],\n",
    "            alias='MSTL')\n",
    "\n",
    "sf = StatsForecast(models=[mstl], freq='H')\n",
    "mstl_cv_df = sf.cross_validation(\n",
    "    h=24, \n",
    "    df=df_train, \n",
    "    n_windows=7,\n",
    "    step_size=24\n",
    ")\n",
    "\n",
    "eval_df = mstl_cv_df.drop(['ds', 'cutoff'], axis=1)\n",
    "evaluation = evaluate(df=eval_df, metrics=[mae, smape])\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and predict with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.utils import PredictionIntervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best models to fit and predict\n",
    "\n",
    "mlf = MLForecast(\n",
    "    models = models, \n",
    "    freq='H',\n",
    "    target_transforms=[Differences([24, 168])],\n",
    "    lags=[1,12,24,168],\n",
    "    lag_transforms={  \n",
    "        1: [ExpandingMean()],\n",
    "        24: [RollingMean(window_size=24)],\n",
    "    },\n",
    "    date_features=['month', 'hour', 'dayofweek']\n",
    ")\n",
    "\n",
    "mlf.fit(\n",
    "    df = df_train,\n",
    "    prediction_intervals=PredictionIntervals(n_windows=4, h=24)\n",
    ")\n",
    "\n",
    "levels = [80] \n",
    "preds = mlf.predict(24, level=levels)\n",
    "preds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.merge(df_test[['ds', 'y']], on='ds', how='left')\n",
    "\n",
    "eval_df = preds.drop(['ds'], axis=1)\n",
    "evaluation = evaluate(df=eval_df, metrics=[mae, smape], models=['lgbm', 'knn'])\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing our ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values, show=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.callbacks import SaveFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitbang-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

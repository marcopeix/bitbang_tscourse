{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env PYTORCH_ENABLE_MPS_FALLBACK=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utilsforecast.losses import *\n",
    "from utilsforecast.evaluation import evaluate\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NBEATS, NHITS, NBEATSx\n",
    "from neuralforecast.losses.pytorch import *\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"NIXTLA_ID_AS_COL\"] = \"true\"\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/marcopeix/TimeSeriesForecastingUsingFoundationModels/refs/heads/main/data/walmart_sales_small.csv\"\n",
    "\n",
    "df = pd.read_csv(url, parse_dates=[\"Date\"])\n",
    "df = df.rename(columns={\"Store\": \"unique_id\", \"Date\":\"ds\", \"Weekly_Sales\":\"y\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,9))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    plot_df = df[df['unique_id'] == i+1]\n",
    "\n",
    "    ax.plot(plot_df['ds'], plot_df['y'])\n",
    "    ax.set_title(f'Store {i+1}')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Weekly Sales ($)')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBEATS\n",
    "\n",
    "nf = NeuralForecast(models=models, freq='W')\n",
    "\n",
    "cv_df = nf.cross_validation(df, n_windows=10, step_size=8)\n",
    "cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,9))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    plot_df = df[df['unique_id'] == i+1]\n",
    "    cv_plot_df = cv_df[cv_df['unique_id'] == i+1]\n",
    "\n",
    "    ax.plot(plot_df['ds'], plot_df['y'])\n",
    "    ax.plot(cv_plot_df['ds'], cv_plot_df['NBEATS'], ls='--', label='NBEATS')\n",
    "    ax.legend()\n",
    "    ax.set_title(f'Store {i+1}')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Weekly Sales ($)')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = cv_df.drop(['ds', 'cutoff'], axis=1)\n",
    "evaluation = evaluate(df=eval_df, metrics=[mae, smape])\n",
    "evaluation = evaluation.drop(['unique_id'], axis=1).groupby('metric').mean().reset_index()\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretable NBEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = df.query(\"unique_id == 1\")\n",
    "Y_train_df = Y_df[:-32]\n",
    "Y_test_df = Y_df[-32:]\n",
    "\n",
    "# Interpretable NBEATS\n",
    "\n",
    "\n",
    "nf = NeuralForecast(models=models, freq='W')\n",
    "nf.fit(df=Y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nf.models[0]\n",
    "dataset, *_ = TimeSeriesDataset.from_df(df=Y_train_df)\n",
    "y_hat = model.decompose(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(10, 7))\n",
    "\n",
    "ax[0].plot(Y_test_df['y'].values, label='True', linewidth=4)\n",
    "ax[0].plot(y_hat.sum(axis=1).flatten(), label='Forecast', color=\"#7B3841\")\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel('Harmonic Signal')\n",
    "\n",
    "ax[1].plot(y_hat[0,1]+y_hat[0,0], label='stack1', color=\"green\")\n",
    "ax[1].set_ylabel('NBEATSx Trend Stack')\n",
    "\n",
    "ax[2].plot(y_hat[0,2], label='stack2', color=\"orange\")\n",
    "ax[2].set_ylabel('NBEATSx Seasonality Stack')\n",
    "ax[2].set_xlabel(r'Prediction $\\tau \\in \\{t+1,..., t+H\\}$')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NHITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NHITS\n",
    "\n",
    "nf = NeuralForecast(models=models, freq='W')\n",
    "\n",
    "cv_df = nf.cross_validation(df, n_windows=10, step_size=8)\n",
    "cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,9))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    plot_df = df[df['unique_id'] == i+1]\n",
    "    cv_plot_df = cv_df[cv_df['unique_id'] == i+1]\n",
    "\n",
    "    ax.plot(plot_df['ds'], plot_df['y'])\n",
    "    ax.plot(cv_plot_df['ds'], cv_plot_df['NHITS'], ls='--', label='NHITS')\n",
    "    ax.legend()\n",
    "    ax.set_title(f'Store {i+1}')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Weekly Sales ($)')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = cv_df.drop(['ds', 'cutoff'], axis=1)\n",
    "evaluation = evaluate(df=eval_df, metrics=[mae, smape])\n",
    "evaluation = evaluation.drop(['unique_id'], axis=1).groupby('metric').mean().reset_index()\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposable NHITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposable NHITS\n",
    "\n",
    "\n",
    "nf = NeuralForecast(models=models, freq='W')\n",
    "nf.fit(df=Y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nf.models[0]\n",
    "dataset, *_ = TimeSeriesDataset.from_df(df = Y_train_df)\n",
    "y_hat = model.decompose(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(10, 7))\n",
    "\n",
    "ax[0].plot(Y_test_df['y'].values, label='True', linewidth=4)\n",
    "ax[0].plot(y_hat.sum(axis=1).flatten(), label='Forecast', color=\"#7B3841\")\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel('Harmonic Signal')\n",
    "\n",
    "ax[1].plot(y_hat[0,1]+y_hat[0,0], label='stack1', color=\"green\")\n",
    "ax[1].set_ylabel('NHITS Stack 1')\n",
    "\n",
    "ax[2].plot(y_hat[0,2], label='stack2', color=\"orange\")\n",
    "ax[2].set_ylabel('NHITS Stack 2')\n",
    "ax[2].set_xlabel(r'Prediction $\\tau \\in \\{t+1,..., t+H\\}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilistic NHITS\n",
    "\n",
    "nf = NeuralForecast(models=models, freq='W')\n",
    "\n",
    "nf.fit(df=Y_train_df)\n",
    "preds = nf.predict()\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(Y_test_df['ds'], Y_test_df['y'])\n",
    "ax.plot(preds['ds'], preds['NHITS-median'], ls='--', label='NHITS')\n",
    "ax.fill_between(preds['ds'], preds['NHITS-lo-90'], preds['NHITS-hi-90'], color='green', alpha=0.2)\n",
    "ax.legend()\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting with exogenous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futr_exog_df = nf.make_future_dataframe()\n",
    "futr_exog_df['Holiday_Flag'] = Y_test_df['Holiday_Flag'].values\n",
    "\n",
    "horizon = 32 \n",
    "models = [\n",
    "    NHITS(\n",
    "        h = horizon,\n",
    "        input_size = 2*horizon,\n",
    "        # Exog features\n",
    "        scaler_type = 'robust'),\n",
    "    NBEATSx(\n",
    "        h = horizon,\n",
    "        input_size = 2*horizon,\n",
    "        # Exog features\n",
    "        scaler_type = 'robust',)\n",
    "]\n",
    "\n",
    "nf = NeuralForecast(models=models, freq='W')\n",
    "\n",
    "nf.fit(df=Y_train_df)\n",
    "futr_exog_df = nf.make_future_dataframe()\n",
    "futr_exog_df['Holiday_Flag'] = Y_test_df['Holiday_Flag'].values\n",
    "preds = nf.predict(futr_df=futr_exog_df)\n",
    "preds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(preds['ds'], Y_test_df['y'])\n",
    "ax.plot(preds['ds'], preds['NHITS'], ls='--', label='NHITS')\n",
    "ax.plot(preds['ds'], preds['NBEATSx'], ls=':', label='NBEATSx')\n",
    "ax.legend()\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['y'] = Y_test_df['y'].values\n",
    "\n",
    "evaluation = evaluate(df=preds, metrics=[mae, smape])\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetsforecast.m4 import M4\n",
    "\n",
    "Y_df, _, _ = M4.load(directory=\"./\", group=\"Hourly\")\n",
    "Y_df[\"ds\"] = Y_df.groupby(\"unique_id\")[\"ds\"].transform(\n",
    "    lambda x: pd.date_range(start=\"1970-01-01\", periods=len(x), freq=\"h\")\n",
    ")\n",
    "Y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 48\n",
    "stacks = 3\n",
    "models = [\n",
    "    NHITS(\n",
    "        input_size=5 * horizon,\n",
    "        h=horizon,\n",
    "        max_steps=1000,\n",
    "        stack_types=stacks * [\"identity\"],\n",
    "        n_blocks=stacks * [1],\n",
    "        mlp_units=[[256, 256] for _ in range(stacks)],\n",
    "        n_pool_kernel_size=stacks * [1],\n",
    "        batch_size=32,\n",
    "        scaler_type=\"standard\",\n",
    "        n_freq_downsample=[12, 4, 1],\n",
    "    )\n",
    "]\n",
    "nf = NeuralForecast(models=models, freq=\"h\")\n",
    "nf.fit(df=Y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'https://raw.githubusercontent.com/panambY/Hourly_Energy_Consumption/master/data/PJM_Load_hourly.csv'\n",
    "df = pd.read_csv(data_url, parse_dates=['Datetime'])\n",
    "df.columns = ['ds', 'y']\n",
    "df.insert(0, 'unique_id', 'PJM')\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "df = df.sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['ds'][-700:], df['y'][-700:])\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Electricity consumption (MW)')\n",
    "ax.set_title('Hourly electricity consumption')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make input dataframe\n",
    "\n",
    "preds = nf.predict(df=input_df)\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['ds'][-300:], df['y'][-300:])\n",
    "ax.plot(preds['ds'], preds['NHITS'], ls='--', label='NHITS')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Electricity consumption (MW)')\n",
    "ax.set_title('Hourly electricity consumption')\n",
    "ax.legend()\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 48\n",
    "stacks = 3\n",
    "models = [\n",
    "    NHITS(\n",
    "        input_size=5 * horizon,\n",
    "        h=horizon,\n",
    "        max_steps=1000,\n",
    "        stack_types=stacks * [\"identity\"],\n",
    "        n_blocks=stacks * [1],\n",
    "        mlp_units=[[256, 256] for _ in range(stacks)],\n",
    "        n_pool_kernel_size=stacks * [1],\n",
    "        batch_size=32,\n",
    "        scaler_type=\"standard\",\n",
    "        n_freq_downsample=[12, 4, 1],\n",
    "    )\n",
    "]\n",
    "nf = NeuralForecast(models=models, freq=\"h\")\n",
    "nf.fit(df=input_df)\n",
    "preds_trained = nf.predict()\n",
    "preds_trained.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df['ds'][-300:], df['y'][-300:])\n",
    "ax.plot(preds['ds'], preds['NHITS'], ls='--', label='NHITS - pretrained')\n",
    "ax.plot(preds_trained['ds'], preds_trained['NHITS'], ls=':', label='NHITS')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Electricity consumption (MW)')\n",
    "ax.set_title('Hourly electricity consumption')\n",
    "ax.legend()\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[-48:]\n",
    "test_df['NHITS-pretrained'] = preds['NHITS'].values\n",
    "test_df['NHITS'] = preds_trained['NHITS'].values\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = evaluate(df=test_df, metrics=[mae, smape])\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-sample preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(input_df['ds'][-300:], input_df['y'][-300:])\n",
    "ax.plot(insample_preds['ds'][-300:], insample_preds['NHITS'][-300:], ls='--', label='NHITS')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Electricity consumption (MW)')\n",
    "ax.set_title('Hourly electricity consumption')\n",
    "ax.legend()\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.utils import AirPassengersDF\n",
    "\n",
    "Y_df = AirPassengersDF\n",
    "Y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(Y_df['ds'], Y_df['y'])\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Number of air passengers')\n",
    "ax.legend()\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from neuralforecast.auto import AutoNHITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NHITS config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize auto model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = NeuralForecast(models=[model], freq='M')\n",
    "nf.fit(df=Y_df, val_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trials info\n",
    "\n",
    "config_cols = [col for col in results.columns if col.startswith('config')]\n",
    "columns_to_keep = ['loss', 'train_loss'] + config_cols\n",
    "existing_columns = [col for col in columns_to_keep if col in results.columns]\n",
    "filtered_results = results[existing_columns]\n",
    "best_runs = filtered_results.sort_values('loss', ascending=True).head(5)\n",
    "best_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitbang-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
